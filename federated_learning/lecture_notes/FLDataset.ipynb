{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db620031",
   "metadata": {},
   "source": [
    "# IID 와 Non-IID\n",
    "IID(IIndependent and Identically Distributed)는 데이터들이 서로 아무런 관련이 없고, 균일하게 분포되어있는 데이터 분포를 말함\n",
    "MINIST예제에서는 0-9 까지의 클래스들을 균등하게 랜덤 추출한 서브 데이터셋을 말함\n",
    "\n",
    "Non-IID(Non-Independent and Identically Distributed) 불균형 데이터 분포\n",
    "연합 학습 관련 자료를 보면 Non-IID 세팅에 대한 성능 평가가 꼭 나오는데 연합학습에서 각 클라이언트가 보유한 데이터가 IID세팅처럼 이상적이지 않을 것이기 때문임\n",
    "그래서 Non-IID 세팅은 어떤 클라이언트에는 0 ~ 3 클래스의 데이터만, 4 ~ 7까지의 데이터만을 추출하여 클래스 간 불균형 데이터 분포를 각 클라이언트의 모델에서 학습할 수 있도록 세팅을 하는 것이다. \n",
    "그렇기에 Non-IID 세팅이 IID세팅보다 성능이 더 낮을 수 밖에 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f45511f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "467719a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnistIID(dataset, num_clients):\n",
    "    images = int(len(dataset)/num_clients) #clients가 10개일경우에는 6000개\n",
    "    clients_dict, indices = {}, [i for i in range(len(dataset))]\n",
    "    for i in range(num_clients):\n",
    "        np.random.seed(i) #랜덤 시드를 고정하여\n",
    "        #총 60,000개 indices에서 60000/num_clients로 나눠준 수 만큼 랜덤 균등 분포로 추출함\n",
    "        clients_dict[i] = set(np.random.choice(indices, images, replace=False)) #random.choice함수가 그역할\n",
    "        indices = list(set(indices) - clients_dict[i]) #선택한 인덱스에 해당하는 데이터를 추출하려는 곳에서 제거함\n",
    "    return clients_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2553ef21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnistNonIID(dataset, num_clients, test=False):\n",
    "    classes, images = 100, 600 #10개의 클라이언트가 10개의 클래스를 선택하면 총 100개의 클래스들을, 600개씩 추출한다.\n",
    "    if test:\n",
    "        classes, images = 20, 500    \n",
    "    classes_idx = [i for i in range(classes)] # 0~99 classes idx 생성\n",
    "    clients_dict = {i: np.array([]) for i in range(num_clients)} # 클라이언트 수만큼 생성 10개로 가정\n",
    "    indices = np.arange(classes*images) #60,000개 이미지 순서 \n",
    "    \n",
    "    unsorted_labels = dataset.train_labels.numpy() #훈련 데이터의 클래스 순서 그대로 가져오기\n",
    "    \n",
    "    if test:\n",
    "        unsorted_labels = dataset.test_labels.numpy()\n",
    "    \n",
    "    indices_unsorted_labels = np.vstack((indices, unsorted_labels)) # 60,000개 이미지와 레이블 번호가 같이 세팅됨\n",
    "    indices_labels = indices_unsorted_labels[:,indices_unsorted_labels[1,:].argsort()] #두번째 행을 기준으로 정렬\n",
    "    indices = indices_labels[0,:]\n",
    "    \n",
    "    for i in range(num_clients):\n",
    "        temp = set(np.random.choice(classes_idx, 2, replace=False)) #2개의 추출 기준을 획득\n",
    "        classes_idx = list(set(classes_idx) - temp) # 추출된 2개 기준을 삭제\n",
    "        for t in temp:\n",
    "            clients_dict[i] = np.concatenate(\n",
    "                (clients_dict[i], indices[t*images:(t+1)*images]), axis=0) #선택된 추출 기준별 600개를 선택해서 추출\n",
    "    return clients_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e829c97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnistNonIIDUnequal(dataset, num_clients, test=False):\n",
    "    classes, images = 100, 600 #total60k\n",
    "    if test:\n",
    "        classes, images = 200, 50\n",
    "    classes_idx = [i for i in range(classes)]\n",
    "    clients_dict = {i: np.array([]) for i in range(num_clients)}\n",
    "    indices = np.arange(classes*images)\n",
    "    unsorted_labels = dataset.train_labels.numpy()\n",
    "\n",
    "    indices_unsorted_labels = np.vstack((indices, unsorted_labels))\n",
    "    indices_labels = indices_unsorted_labels[:, indices_unsorted_labels[1, :].argsort()]\n",
    "    indices = indices_labels[0, :]\n",
    "\n",
    "    min_cls_per_client = 1\n",
    "    max_cls_per_client = 10\n",
    "    #1~10까지 랜덤하게 선택한 숫자를 차례대로 출력\n",
    "    random_selected_classes = np.random.randint(min_cls_per_client, max_cls_per_client+1, size=num_clients)\n",
    "    #해당 수/전체 수를 하여 %를 구하고 거기에 원하는 전체 갯수를 곱하면 얻을 갯수를 구할 수 있음\n",
    "    random_selected_classes = np.around(random_selected_classes / sum(random_selected_classes) * classes)\n",
    "    #소수점으로 구해지기때문에 타입 변환\n",
    "    random_selected_classes = random_selected_classes.astype(int)\n",
    "    \n",
    "    #예외 처리 원하는 갯수보다 많이 획득됬을 경우\n",
    "    if sum(random_selected_classes) > classes:\n",
    "        for i in range(num_clients):\n",
    "            np.random.seed(i)\n",
    "            #적어도 1개의 클래스를 갖도록 추출 1개의 클래스 우선 추출\n",
    "            temp = set(np.random.choice(classes_indx, 1, replace=False))\n",
    "            classes_indx = list(set(classes_indx) - temp)\n",
    "            for t in temp:\n",
    "                clients_dict[i] = np.concatenate((clients_dict[i], indices[t*images:(t+1)*images]), axis=0)\n",
    "                \n",
    "        random_selected_classes = random_selected_classes-1\n",
    "        \n",
    "        for i in range(num_clients):\n",
    "            if len(classes_idx) == 0: #추출해야할 것들을 모두 추출하였음\n",
    "                continue\n",
    "            class_size = random_selected_classes[i] #랜덤하게 결정한 classes size가 idx크기보다 크면 크기를 최대값에 맞춰줌\n",
    "            if class_size > len(classes_idx): \n",
    "                class_size = len(classes_idx)\n",
    "            np.random.seed(i)\n",
    "            temp = set(np.random.choice(classes_idx, class_size, replace=False))\n",
    "            classes_indx = list(set(classes_idx) - temp)\n",
    "            for t in temp:\n",
    "                users_dict[i] = np.concatenate((clients_dict[i], indices[t*images:(t+1)*images]), axis=0)\n",
    "    #적게 혹은 같게 획득했을 경우\n",
    "    else:\n",
    "\n",
    "        for i in range(num_clients):\n",
    "            class_size = random_selected_classes[i]\n",
    "            np.random.seed(i)\n",
    "            temp = set(np.random.choice(classes_indx, class_size, replace=False))\n",
    "            classes_indx = list(set(classes_indx) - temp)\n",
    "            for t in temp:\n",
    "                clients_dict[i] = np.concatenate((clients_dict[i], indices[t*images:(t+1)*images]), axis=0)\n",
    "\n",
    "        if len(classes_idx) > 0: #idx에서 아무도 가져가지 않았을때(남아있는 경우)\n",
    "            class_size = len(classes_indx)\n",
    "            k = min(clients_dict, key=lambda x: len(clients_dict.get(x)))\n",
    "            temp = set(np.random.choice(classes_idx, class_size, replace=False))\n",
    "            classes_idx = list(set(classes_idx) - temp)\n",
    "            for t in temp:\n",
    "                clients_dict[k] = np.concatenate((clients_dict[k], indices[t*images:(t+1)*images]), axis=0)\n",
    "\n",
    "    return clients_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d68fd800",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(num_clients, iidtype):\n",
    "    trainset = datasets.MNIST(root='./',\n",
    "                          train=True,\n",
    "                          transform=transforms.ToTensor(),\n",
    "                          download=True)\n",
    "    testset = datasets.MNIST(root='./',\n",
    "                          train=False,\n",
    "                          transform=transforms.ToTensor(),\n",
    "                          download=True)\n",
    "    train_group, test_group = None, None\n",
    "    if iidtype == 'iid' :\n",
    "        traingroup = mnistIID(trainset, num_clients)\n",
    "        testgroup = mnistIID(testset, num_clients)\n",
    "    elif iidtype == 'noniid':\n",
    "        traingroup = mnistNonIID(trainset, num_clients)\n",
    "        testgroup = mnistNonIID(testset, num_clients, True)\n",
    "    \n",
    "    return trainset, testset, traingroup, testgroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "632ef1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FedDataset(Dataset):\n",
    "    def __init__(self, dataset, idx):\n",
    "        self.dataset = dataset\n",
    "        self.idx = [int(i) for i in idx]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.idx)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        images, label = self.dataset[self.idx[item]]\n",
    "        return torch.tensor(images).clone().detach(), torch.tensor(label).clone().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b82e76f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getImgs(dataset, indices, batch_size):\n",
    "    return DataLoader(FedDataset(dataset, indices), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "168f1e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(dataset, indices):\n",
    "    return FedDataset(dataset, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff95b14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pysyft",
   "language": "python",
   "name": "pysyft"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
