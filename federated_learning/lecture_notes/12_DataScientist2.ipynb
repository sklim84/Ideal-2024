{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1203a051",
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft as sy\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41544086",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé§  üé∏  ‚ô™‚ô™‚ô™ Joining Duet ‚ô´‚ô´‚ô´  üéª  üéπ\n",
      "\n",
      "‚ô´‚ô´‚ô´ >\u001b[93m DISCLAIMER\u001b[0m: \u001b[1mDuet is an experimental feature currently in beta.\n",
      "‚ô´‚ô´‚ô´ > Use at your own risk.\n",
      "\u001b[0m\n",
      "\u001b[1m\n",
      "    > ‚ù§Ô∏è \u001b[91mLove\u001b[0m \u001b[92mDuet\u001b[0m? \u001b[93mPlease\u001b[0m \u001b[94mconsider\u001b[0m \u001b[95msupporting\u001b[0m \u001b[91mour\u001b[0m \u001b[93mcommunity!\u001b[0m\n",
      "    > https://github.com/sponsors/OpenMined\u001b[1m\n",
      "\n",
      "‚ô´‚ô´‚ô´ > Punching through firewall to OpenGrid Network Node at:\n",
      "‚ô´‚ô´‚ô´ > http://ec2-18-218-7-180.us-east-2.compute.amazonaws.com:5000\n",
      "‚ô´‚ô´‚ô´ >\n",
      "‚ô´‚ô´‚ô´ > ...waiting for response from OpenGrid Network... \n",
      "‚ô´‚ô´‚ô´ > \u001b[92mDONE!\u001b[0m\n",
      "\n",
      "‚ô´‚ô´‚ô´ > \u001b[95mSTEP 1:\u001b[0m Send the following Duet Client ID to your duet partner!\n",
      "‚ô´‚ô´‚ô´ > Duet Client ID: \u001b[1m3063b4e283cf2f1f2976c6c10ad69033\u001b[0m\n",
      "\n",
      "‚ô´‚ô´‚ô´ > ...waiting for partner to connect...\n",
      "\n",
      "‚ô´‚ô´‚ô´ > \u001b[92mCONNECTED!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "duet1 = sy.join_duet(\"d65b5ca1d2319946bf05088277bffe1b\")\n",
    "sy.logger.add(sink=\"./syft_ds.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62b20dd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé§  üé∏  ‚ô™‚ô™‚ô™ Joining Duet ‚ô´‚ô´‚ô´  üéª  üéπ\n",
      "\n",
      "‚ô´‚ô´‚ô´ >\u001b[93m DISCLAIMER\u001b[0m: \u001b[1mDuet is an experimental feature currently in beta.\n",
      "‚ô´‚ô´‚ô´ > Use at your own risk.\n",
      "\u001b[0m\n",
      "\u001b[1m\n",
      "    > ‚ù§Ô∏è \u001b[91mLove\u001b[0m \u001b[92mDuet\u001b[0m? \u001b[93mPlease\u001b[0m \u001b[94mconsider\u001b[0m \u001b[95msupporting\u001b[0m \u001b[91mour\u001b[0m \u001b[93mcommunity!\u001b[0m\n",
      "    > https://github.com/sponsors/OpenMined\u001b[1m\n",
      "\n",
      "‚ô´‚ô´‚ô´ > Punching through firewall to OpenGrid Network Node at:\n",
      "‚ô´‚ô´‚ô´ > http://ec2-18-218-7-180.us-east-2.compute.amazonaws.com:5000\n",
      "‚ô´‚ô´‚ô´ >\n",
      "‚ô´‚ô´‚ô´ > ...waiting for response from OpenGrid Network... \n",
      "‚ô´‚ô´‚ô´ > \u001b[92mDONE!\u001b[0m\n",
      "\n",
      "‚ô´‚ô´‚ô´ > \u001b[95mSTEP 1:\u001b[0m Send the following Duet Client ID to your duet partner!\n",
      "‚ô´‚ô´‚ô´ > Duet Client ID: \u001b[1m38e56b1696f7651cef222d3777b229f0\u001b[0m\n",
      "\n",
      "‚ô´‚ô´‚ô´ > ...waiting for partner to connect...\n",
      "\n",
      "‚ô´‚ô´‚ô´ > \u001b[92mCONNECTED!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "duet2 = sy.join_duet(\"90f5a918a6706ecc9e579b9a6c130f90\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9176bf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13cfcd53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Description</th>\n",
       "      <th>object_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;UID: 302ab3e42798406aa8e3c8c7cdca4a2a&gt;</td>\n",
       "      <td>[x_train]</td>\n",
       "      <td>Dataset of 30000 samples</td>\n",
       "      <td>&lt;class 'torch.Tensor'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;UID: 3191f50488ea46d6b4377a1de71e0dbb&gt;</td>\n",
       "      <td>[y_train]</td>\n",
       "      <td>Dataset of 30000 samples</td>\n",
       "      <td>&lt;class 'torch.Tensor'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;UID: 67adb114b96b4a67ac9d6f4e729f0ec1&gt;</td>\n",
       "      <td>[x_test]</td>\n",
       "      <td>Dataset of 5000 samples</td>\n",
       "      <td>&lt;class 'torch.Tensor'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;UID: b0611b7a9c1c4c93b13253ab5e1cc5fe&gt;</td>\n",
       "      <td>[y_test]</td>\n",
       "      <td>Dataset of 5000 samples</td>\n",
       "      <td>&lt;class 'torch.Tensor'&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        ID       Tags  \\\n",
       "0  <UID: 302ab3e42798406aa8e3c8c7cdca4a2a>  [x_train]   \n",
       "1  <UID: 3191f50488ea46d6b4377a1de71e0dbb>  [y_train]   \n",
       "2  <UID: 67adb114b96b4a67ac9d6f4e729f0ec1>   [x_test]   \n",
       "3  <UID: b0611b7a9c1c4c93b13253ab5e1cc5fe>   [y_test]   \n",
       "\n",
       "                Description             object_type  \n",
       "0  Dataset of 30000 samples  <class 'torch.Tensor'>  \n",
       "1  Dataset of 30000 samples  <class 'torch.Tensor'>  \n",
       "2   Dataset of 5000 samples  <class 'torch.Tensor'>  \n",
       "3   Dataset of 5000 samples  <class 'torch.Tensor'>  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duet1.store.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc17ae7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Description</th>\n",
       "      <th>object_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;UID: a0f0c6a89a264a64974f84ba1574f980&gt;</td>\n",
       "      <td>[x_train]</td>\n",
       "      <td>Dataset of 30000 samples</td>\n",
       "      <td>&lt;class 'torch.Tensor'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;UID: ce8affff3db3466389b2dd8617f333d9&gt;</td>\n",
       "      <td>[y_train]</td>\n",
       "      <td>Dataset of 30000 samples</td>\n",
       "      <td>&lt;class 'torch.Tensor'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;UID: 5f531de3a296488fbcd0968bda16879f&gt;</td>\n",
       "      <td>[x_test]</td>\n",
       "      <td>Dataset of 5000 samples</td>\n",
       "      <td>&lt;class 'torch.Tensor'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;UID: 9cfef27ded0343fba8c3c1a7dc8f34e8&gt;</td>\n",
       "      <td>[y_test]</td>\n",
       "      <td>Dataset of 5000 samples</td>\n",
       "      <td>&lt;class 'torch.Tensor'&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        ID       Tags  \\\n",
       "0  <UID: a0f0c6a89a264a64974f84ba1574f980>  [x_train]   \n",
       "1  <UID: ce8affff3db3466389b2dd8617f333d9>  [y_train]   \n",
       "2  <UID: 5f531de3a296488fbcd0968bda16879f>   [x_test]   \n",
       "3  <UID: 9cfef27ded0343fba8c3c1a7dc8f34e8>   [y_test]   \n",
       "\n",
       "                Description             object_type  \n",
       "0  Dataset of 30000 samples  <class 'torch.Tensor'>  \n",
       "1  Dataset of 30000 samples  <class 'torch.Tensor'>  \n",
       "2   Dataset of 5000 samples  <class 'torch.Tensor'>  \n",
       "3   Dataset of 5000 samples  <class 'torch.Tensor'>  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duet2.store.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6744aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cnn Î™®Îç∏ÏùÑ ÏÇ¨Ïö©\n",
    "class SyNet(sy.Module):\n",
    "    def __init__(self, torch_ref):\n",
    "        super(SyNet, self).__init__(torch_ref=torch_ref)\n",
    "        self.conv1 = self.torch_ref.nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = self.torch_ref.nn.Conv2d(32, 64, 3, 1) \n",
    "        self.conv3 = self.torch_ref.nn.Conv2d(64, 128, 3 ,1)\n",
    "        \n",
    "        self.dropout1 = self.torch_ref.nn.Dropout2d(0.25)\n",
    "        self.dropout2 = self.torch_ref.nn.Dropout2d(0.5)\n",
    "        \n",
    "        self.fc1 = self.torch_ref.nn.Linear(9216, 128)\n",
    "        self.fc2 = self.torch_ref.nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # ImgIn shape=(?, 1, 28, 28)\n",
    "        # Conv     -> (?, 32, 28, 28)\n",
    "        x = self.conv1(x)\n",
    "        x = self.torch_ref.nn.functional.relu(x)\n",
    "        # ImgIn shape=(?, 32, 28, 28)\n",
    "        # Conv     -> (?, 64, 28, 28)\n",
    "        # Pool     -> (?, 64, 14, 14)\n",
    "        x = self.conv2(x)\n",
    "        x = self.torch_ref.nn.functional.relu(x)\n",
    "        x = self.torch_ref.nn.functional.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        # Flatten     -> (?, 64*14*14)\n",
    "        x = self.torch_ref.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.torch_ref.nn.functional.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = self.torch_ref.nn.functional.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab9e68bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÌïôÏäµÏóê ÏÇ¨Ïö©Îê† Ïù∏ÏûêÎì§ ÏÑ§Ï†ï\n",
    "args = {\n",
    "    \"images\": 60000,\n",
    "    \"clients\": 2,\n",
    "    \"rounds\": 4,\n",
    "    \"batch_size\": 64,\n",
    "    \"test_batch_size\": 5000,\n",
    "    \"epochs\": 4,\n",
    "    \"lr\": 1.0,\n",
    "    \"gamma\": 0.7,\n",
    "    \"dry_run\": False,\n",
    "    \"seed\": 42, # the meaning of life\n",
    "    \"log_interval\": 10,\n",
    "    \"torch_seed\": 0,\n",
    "    \"save_model\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff477114",
   "metadata": {},
   "outputs": [],
   "source": [
    "clients = []\n",
    "\n",
    "for i in range(args['clients']):\n",
    "    clients.append({'duet': eval(\"duet{}\".format(i+1))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "698390fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(args['torch_seed'])\n",
    "local_model = SyNet(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de871de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000 30000\n",
      "30000 30000\n"
     ]
    }
   ],
   "source": [
    "#train Îç∞Ïù¥ÌÑ∞ÏÖã ÏñªÍ∏∞\n",
    "train_kwargs = {\n",
    "    \"batch_size\": args[\"batch_size\"],\n",
    "}\n",
    "print(len(duet1.store[0]), len(duet1.store[1]))\n",
    "train_data_ptr1=torch.utils.data.TensorDataset(duet1.store[0].get_copy(), duet1.store[1].get_copy())\n",
    "clients[0]['train_data_ptr'] = train_data_ptr1\n",
    "clients[0]['train_loader_ptr'] = torch.utils.data.DataLoader(train_data_ptr1,**train_kwargs)\n",
    "\n",
    "print(len(duet2.store[0]), len(duet2.store[1]))\n",
    "train_data_ptr2=torch.utils.data.TensorDataset(duet2.store[0].get_copy(), duet2.store[1].get_copy())\n",
    "clients[1]['train_data_ptr'] = train_data_ptr2\n",
    "clients[1]['train_loader_ptr'] = torch.utils.data.DataLoader(train_data_ptr2,**train_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "68baf52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 5000\n",
      "5000 5000\n"
     ]
    }
   ],
   "source": [
    "#testÎç∞Ïù¥ÌÑ∞ÏÖã ÏñªÍ∏∞\n",
    "test_kwargs = {\n",
    "    \"batch_size\": args[\"test_batch_size\"],\n",
    "}\n",
    "#duetÏóê 2Î≤àÏß∏, 3Î≤àÏß∏Í∞Ä x_test, y_test\n",
    "print(len(duet1.store[2]), len(duet1.store[3]))\n",
    "test_data_ptr1=torch.utils.data.TensorDataset(duet1.store[2].get_copy(), duet1.store[3].get_copy())\n",
    "clients[0]['test_data_ptr'] = test_data_ptr1\n",
    "clients[0]['test_loader_ptr'] = torch.utils.data.DataLoader(test_data_ptr1,**test_kwargs)\n",
    "\n",
    "print(len(duet2.store[2]), len(duet2.store[3]))\n",
    "test_data_ptr2=torch.utils.data.TensorDataset(duet2.store[2].get_copy(), duet2.store[3].get_copy())\n",
    "clients[1]['test_data_ptr'] = test_data_ptr2\n",
    "clients[1]['test_loader_ptr'] = torch.utils.data.DataLoader(test_data_ptr2,**train_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55771fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'duet': <Duet: <UID: ae42d5285b3c464aa952f0bed4aaf1b5>>,\n",
       "  'train_data_ptr': <torch.utils.data.dataset.TensorDataset at 0x7fbf1a86b880>,\n",
       "  'train_loader_ptr': <torch.utils.data.dataloader.DataLoader at 0x7fbf1aafd490>,\n",
       "  'test_data_ptr': <torch.utils.data.dataset.TensorDataset at 0x7fbf1a4a24c0>,\n",
       "  'test_loader_ptr': <torch.utils.data.dataloader.DataLoader at 0x7fbf1a865c10>},\n",
       " {'duet': <Duet: <UID: bcb0f6ce100c41b8b02061b5c8c0f365>>,\n",
       "  'train_data_ptr': <torch.utils.data.dataset.TensorDataset at 0x7fbf1a3e6cd0>,\n",
       "  'train_loader_ptr': <torch.utils.data.dataloader.DataLoader at 0x7fbf1a3e6fd0>,\n",
       "  'test_data_ptr': <torch.utils.data.dataset.TensorDataset at 0x7fbf1ab02f40>,\n",
       "  'test_loader_ptr': <torch.utils.data.dataloader.DataLoader at 0x7fbf1b833430>}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "872a750d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, client in enumerate(clients):\n",
    "    client['remote_torch'] = client['duet'].torch\n",
    "    torch.manual_seed(idx)\n",
    "    client['model'] = SyNet(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3c464f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(client, epoch, args):\n",
    "    # + 0.5 lets us math.ceil without the import\n",
    "    train_batches = round((client['train_data_length'] / args[\"batch_size\"]) + 0.5)\n",
    "    print(f\"> Running train in {train_batches} batches\")\n",
    "    if client['remote_model'].is_local:\n",
    "        print(\"Training requires remote model\")\n",
    "        return\n",
    "\n",
    "    client['remote_model'].train()\n",
    "\n",
    "    for batch_idx, data in enumerate(client['train_loader_ptr']):\n",
    "        data_ptr, target_ptr = data[0], data[1]\n",
    "        client['optim'].zero_grad()\n",
    "        output = client['remote_model'](data_ptr)\n",
    "        loss = client['remote_torch'].nn.functional.nll_loss(output, target_ptr)\n",
    "        loss.backward()\n",
    "        client['optim'].step()\n",
    "        loss_item = loss.item()\n",
    "        train_loss = client['duet'].python.Float(0)  # create a remote Float we can use for summation\n",
    "        train_loss += loss_item\n",
    "        if batch_idx % args[\"log_interval\"] == 0:\n",
    "            local_loss = None\n",
    "            local_loss = loss_item.get(\n",
    "                reason=\"To evaluate training progress\",\n",
    "                request_block=True,\n",
    "                timeout_secs=5\n",
    "            )\n",
    "            if local_loss is not None:\n",
    "                print(\"Train Epoch: {} {} {:.4}\".format(epoch, batch_idx, local_loss))\n",
    "            else:\n",
    "                print(\"Train Epoch: {} {} ?\".format(epoch, batch_idx))\n",
    "            if args[\"dry_run\"]:\n",
    "                break\n",
    "        if batch_idx >= train_batches - 1:\n",
    "            print(\"batch_idx >= train_batches, breaking\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0cc95010",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_local(client, model, test_loader, test_data_length):\n",
    "    current_model = None\n",
    "    # download remote model\n",
    "    if not model.is_local:\n",
    "        current_model = client['remote_model'].get(\n",
    "            request_block=True,\n",
    "            reason=\"test evaluation\",\n",
    "            timeout_secs=5\n",
    "        )\n",
    "    else:\n",
    "        current_model = model\n",
    "    # + 0.5 lets us math.ceil without the import\n",
    "    test_batches = round((test_data_length / args[\"test_batch_size\"]) + 0.5)\n",
    "    print(f\"> Running test_local in {test_batches} batches\")\n",
    "    current_model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(test_loader):\n",
    "            output = current_model(data)\n",
    "            iter_loss = torch.nn.functional.nll_loss(output, target, reduction=\"sum\").item()\n",
    "            test_loss = test_loss + iter_loss\n",
    "            pred = output.argmax(dim=1)\n",
    "            total = pred.eq(target).sum().item()\n",
    "            correct += total\n",
    "            if args[\"dry_run\"]:\n",
    "                break\n",
    "                \n",
    "            if batch_idx >= test_batches - 1:\n",
    "                print(\"batch_idx >= test_batches, breaking\")\n",
    "                break\n",
    "\n",
    "    accuracy = correct / test_data_length\n",
    "    print(f\"Test Set Accuracy: {100 * accuracy}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e4b3f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def averageModels(global_model, clients):\n",
    "    client_models = [clients[i]['model'] for i in range(len(clients))]\n",
    "    samples = [clients[i]['samples'] for i in range(len(clients))]\n",
    "    global_dict = global_model.state_dict()\n",
    "    \n",
    "    for k in global_dict.keys():\n",
    "        global_dict[k] = torch.stack([client_models[i].state_dict()[k].float() * samples[i] for i in range(len(client_models))], 0).sum(0)\n",
    "            \n",
    "    global_model.load_state_dict(global_dict)\n",
    "    return global_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1c48c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset size is: 30000\n",
      "Training Dataset size is: 30000\n",
      "Test Dataset size is: 5000\n",
      "Test Dataset size is: 5000\n"
     ]
    }
   ],
   "source": [
    "# normally we would not necessarily know the length of a remote dataset so lets ask for it\n",
    "# so we can pass that to our training loop and know when to stop\n",
    "def get_train_length(train_data_ptr):\n",
    "    train_data_length = len(train_data_ptr)\n",
    "    return train_data_length\n",
    "\n",
    "\n",
    "for client in clients:\n",
    "    client['train_data_length'] = get_train_length(client['train_data_ptr'])\n",
    "    try:\n",
    "        if train_data_length is None:\n",
    "            train_data_length = get_train_length(client['train_data_ptr'])\n",
    "    except NameError:\n",
    "        train_data_length = get_train_length(client['train_data_ptr'])\n",
    "    \n",
    "    client['samples'] = client['train_data_length'] / args['images']\n",
    "    print(f\"Training Dataset size is: {client['train_data_length']}\")\n",
    "    \n",
    "def get_test_length(test_data_ptr):\n",
    "    test_data_length = len(test_data_ptr)\n",
    "    return test_data_length\n",
    "\n",
    "\n",
    "for client in clients:\n",
    "    client['test_data_length'] = get_test_length(client['test_data_ptr'])\n",
    "    try:\n",
    "        if test_data_length is None:\n",
    "            test_data_length = get_test_length(client['test_data_ptr'])\n",
    "    except NameError:\n",
    "        test_data_length = get_test_length(client['test_data_ptr'])\n",
    "    \n",
    "    client['samples'] = client['test_data_length'] / args['images']\n",
    "    print(f\"Test Dataset size is: {client['test_data_length']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bdd7897d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n",
      "Round Number: 1\n",
      "client Number: 0\n",
      "Epoch: 1\n",
      "> Running train in 469 batches\n",
      "Train Epoch: 1 0 0.1347\n",
      "Train Epoch: 1 10 0.3326\n",
      "Train Epoch: 1 20 0.2078\n",
      "Train Epoch: 1 30 0.1253\n",
      "Train Epoch: 1 40 0.08132\n",
      "Train Epoch: 1 50 0.1343\n",
      "Train Epoch: 1 60 0.1576\n",
      "Train Epoch: 1 70 0.07147\n",
      "Train Epoch: 1 80 0.09125\n",
      "Train Epoch: 1 90 0.2886\n",
      "Train Epoch: 1 100 0.1592\n",
      "Train Epoch: 1 110 0.0834\n",
      "Train Epoch: 1 120 0.06519\n",
      "Train Epoch: 1 130 0.07956\n",
      "Train Epoch: 1 140 0.2916\n",
      "Train Epoch: 1 150 0.08925\n",
      "Train Epoch: 1 160 0.07734\n",
      "Train Epoch: 1 170 0.0881\n",
      "Train Epoch: 1 180 0.06535\n",
      "Train Epoch: 1 190 0.05161\n",
      "Train Epoch: 1 200 0.3112\n",
      "Train Epoch: 1 210 0.02376\n",
      "Train Epoch: 1 220 0.0351\n",
      "Train Epoch: 1 230 0.08015\n",
      "Train Epoch: 1 240 0.09655\n",
      "Train Epoch: 1 250 0.1236\n",
      "Train Epoch: 1 260 0.2171\n",
      "Train Epoch: 1 270 0.1569\n",
      "Train Epoch: 1 280 0.1454\n",
      "Train Epoch: 1 290 0.08106\n",
      "Train Epoch: 1 300 0.1014\n",
      "Train Epoch: 1 310 0.07516\n",
      "Train Epoch: 1 320 0.1219\n",
      "Train Epoch: 1 330 0.1637\n",
      "Train Epoch: 1 340 0.1735\n",
      "Train Epoch: 1 350 0.1138\n",
      "Train Epoch: 1 360 0.2234\n",
      "Train Epoch: 1 370 0.1605\n",
      "Train Epoch: 1 380 0.01626\n",
      "Train Epoch: 1 390 0.1462\n",
      "Train Epoch: 1 400 0.1091\n",
      "Train Epoch: 1 410 0.07208\n",
      "Train Epoch: 1 420 0.02082\n",
      "Train Epoch: 1 430 0.02189\n",
      "Train Epoch: 1 440 0.06307\n",
      "Train Epoch: 1 450 0.1116\n",
      "Train Epoch: 1 460 0.003406\n",
      "batch_idx >= train_batches, breaking\n",
      "Epoch time: 62 seconds\n",
      "Round Number: 1\n",
      "client Number: 1\n",
      "Epoch: 1\n",
      "> Running train in 469 batches\n",
      "Train Epoch: 1 0 2.311\n",
      "Train Epoch: 1 10 1.867\n",
      "Train Epoch: 1 20 1.096\n",
      "Train Epoch: 1 30 0.8941\n",
      "Train Epoch: 1 40 0.7997\n",
      "Train Epoch: 1 50 0.4949\n",
      "Train Epoch: 1 60 0.704\n",
      "Train Epoch: 1 70 0.3359\n",
      "Train Epoch: 1 80 0.5427\n",
      "Train Epoch: 1 90 0.7657\n",
      "Train Epoch: 1 100 0.3156\n",
      "Train Epoch: 1 110 0.4907\n",
      "Train Epoch: 1 120 0.3763\n",
      "Train Epoch: 1 130 0.3195\n",
      "Train Epoch: 1 140 0.254\n",
      "Train Epoch: 1 150 0.3679\n",
      "Train Epoch: 1 160 0.1627\n",
      "Train Epoch: 1 170 0.1602\n",
      "Train Epoch: 1 180 0.2947\n",
      "Train Epoch: 1 190 0.123\n",
      "Train Epoch: 1 200 0.3605\n",
      "Train Epoch: 1 210 0.3753\n",
      "Train Epoch: 1 220 0.3467\n",
      "Train Epoch: 1 230 0.2019\n",
      "Train Epoch: 1 240 0.2086\n",
      "Train Epoch: 1 250 0.1444\n",
      "Train Epoch: 1 260 0.1087\n",
      "Train Epoch: 1 270 0.228\n",
      "Train Epoch: 1 280 0.1506\n",
      "Train Epoch: 1 290 0.1847\n",
      "Train Epoch: 1 300 0.2567\n",
      "Train Epoch: 1 310 0.1483\n",
      "Train Epoch: 1 320 0.2531\n",
      "Train Epoch: 1 330 0.1921\n",
      "Train Epoch: 1 340 0.164\n",
      "Train Epoch: 1 350 0.2699\n",
      "Train Epoch: 1 360 0.2797\n",
      "Train Epoch: 1 370 0.3701\n",
      "Train Epoch: 1 380 0.09909\n",
      "Train Epoch: 1 390 0.1186\n",
      "Train Epoch: 1 400 0.1963\n",
      "Train Epoch: 1 410 0.09145\n",
      "Train Epoch: 1 420 0.3178\n",
      "Train Epoch: 1 430 0.04868\n",
      "Train Epoch: 1 440 0.1123\n",
      "Train Epoch: 1 450 0.3012\n",
      "Train Epoch: 1 460 0.004438\n",
      "batch_idx >= train_batches, breaking\n",
      "Epoch time: 62 seconds\n",
      "> Running test_local in 2 batches\n",
      "batch_idx >= test_batches, breaking\n",
      "Test Set Accuracy: 2.5%\n",
      "Round Number: 2\n",
      "client Number: 0\n",
      "Epoch: 1\n",
      "> Running train in 469 batches\n",
      "Train Epoch: 1 0 2.302\n",
      "Train Epoch: 1 10 2.3\n",
      "Train Epoch: 1 20 2.262\n",
      "Train Epoch: 1 30 1.455\n",
      "Train Epoch: 1 40 1.289\n",
      "Train Epoch: 1 50 0.7867\n",
      "Train Epoch: 1 60 1.036\n",
      "Train Epoch: 1 70 0.3663\n",
      "Train Epoch: 1 80 0.9004\n",
      "Train Epoch: 1 90 0.9572\n",
      "Train Epoch: 1 100 0.3493\n",
      "Train Epoch: 1 110 0.3508\n",
      "Train Epoch: 1 120 0.285\n",
      "Train Epoch: 1 130 0.3457\n",
      "Train Epoch: 1 140 0.4183\n",
      "Train Epoch: 1 150 0.296\n",
      "Train Epoch: 1 160 0.4046\n",
      "Train Epoch: 1 170 0.1469\n",
      "Train Epoch: 1 180 0.2691\n",
      "Train Epoch: 1 190 0.2534\n",
      "Train Epoch: 1 200 0.4082\n",
      "Train Epoch: 1 210 0.1599\n",
      "Train Epoch: 1 220 0.1602\n",
      "Train Epoch: 1 230 0.09792\n",
      "Train Epoch: 1 240 0.3162\n",
      "Train Epoch: 1 250 0.1648\n",
      "Train Epoch: 1 260 0.3358\n",
      "Train Epoch: 1 270 0.2472\n",
      "Train Epoch: 1 280 0.2541\n",
      "Train Epoch: 1 290 0.2893\n",
      "Train Epoch: 1 300 0.1226\n",
      "Train Epoch: 1 310 0.2206\n",
      "Train Epoch: 1 320 0.193\n",
      "Train Epoch: 1 330 0.2883\n",
      "Train Epoch: 1 340 0.1912\n",
      "Train Epoch: 1 350 0.176\n",
      "Train Epoch: 1 360 0.2951\n",
      "Train Epoch: 1 370 0.2413\n",
      "Train Epoch: 1 380 0.1694\n",
      "Train Epoch: 1 390 0.3023\n",
      "Train Epoch: 1 400 0.376\n",
      "Train Epoch: 1 410 0.03159\n",
      "Train Epoch: 1 420 0.144\n",
      "Train Epoch: 1 430 0.05375\n",
      "Train Epoch: 1 440 0.08254\n",
      "Train Epoch: 1 450 0.1431\n",
      "Train Epoch: 1 460 0.02887\n",
      "batch_idx >= train_batches, breaking\n",
      "Epoch time: 62 seconds\n",
      "Round Number: 2\n",
      "client Number: 1\n",
      "Epoch: 1\n",
      "> Running train in 469 batches\n",
      "Train Epoch: 1 0 2.301\n",
      "Train Epoch: 1 10 2.302\n",
      "Train Epoch: 1 20 2.263\n",
      "Train Epoch: 1 30 1.981\n",
      "Train Epoch: 1 40 1.352\n",
      "Train Epoch: 1 50 0.8059\n",
      "Train Epoch: 1 60 0.5873\n",
      "Train Epoch: 1 70 0.4941\n",
      "Train Epoch: 1 80 0.3655\n",
      "Train Epoch: 1 90 0.7699\n",
      "Train Epoch: 1 100 0.4131\n",
      "Train Epoch: 1 110 0.5113\n",
      "Train Epoch: 1 120 0.4531\n",
      "Train Epoch: 1 130 0.474\n",
      "Train Epoch: 1 140 0.2184\n",
      "Train Epoch: 1 150 0.3674\n",
      "Train Epoch: 1 160 0.1597\n",
      "Train Epoch: 1 170 0.1583\n",
      "Train Epoch: 1 180 0.2712\n",
      "Train Epoch: 1 190 0.09482\n",
      "Train Epoch: 1 200 0.223\n",
      "Train Epoch: 1 210 0.3269\n",
      "Train Epoch: 1 220 0.2851\n",
      "Train Epoch: 1 230 0.1974\n",
      "Train Epoch: 1 240 0.2663\n",
      "Train Epoch: 1 250 0.1771\n",
      "Train Epoch: 1 260 0.1835\n",
      "Train Epoch: 1 270 0.3397\n",
      "Train Epoch: 1 280 0.136\n",
      "Train Epoch: 1 290 0.2264\n",
      "Train Epoch: 1 300 0.2309\n",
      "Train Epoch: 1 310 0.1857\n",
      "Train Epoch: 1 320 0.226\n",
      "Train Epoch: 1 330 0.1801\n",
      "Train Epoch: 1 340 0.155\n",
      "Train Epoch: 1 350 0.2314\n",
      "Train Epoch: 1 360 0.4129\n",
      "Train Epoch: 1 370 0.1786\n",
      "Train Epoch: 1 380 0.06945\n",
      "Train Epoch: 1 390 0.15\n",
      "Train Epoch: 1 400 0.2314\n",
      "Train Epoch: 1 410 0.17\n",
      "Train Epoch: 1 420 0.3824\n",
      "Train Epoch: 1 430 0.1408\n",
      "Train Epoch: 1 440 0.135\n",
      "Train Epoch: 1 450 0.2303\n",
      "Train Epoch: 1 460 0.0125\n",
      "batch_idx >= train_batches, breaking\n",
      "Epoch time: 62 seconds\n",
      "> Running test_local in 2 batches\n",
      "batch_idx >= test_batches, breaking\n",
      "Test Set Accuracy: 2.52%\n",
      "Round Number: 3\n",
      "client Number: 0\n",
      "Epoch: 1\n",
      "> Running train in 469 batches\n",
      "Train Epoch: 1 0 2.293\n",
      "Train Epoch: 1 10 2.265\n",
      "Train Epoch: 1 20 1.088\n",
      "Train Epoch: 1 30 0.4936\n",
      "Train Epoch: 1 40 0.6117\n",
      "Train Epoch: 1 50 0.2814\n",
      "Train Epoch: 1 60 0.694\n",
      "Train Epoch: 1 70 0.277\n",
      "Train Epoch: 1 80 0.2776\n",
      "Train Epoch: 1 90 0.7072\n",
      "Train Epoch: 1 100 0.1415\n",
      "Train Epoch: 1 110 0.1926\n",
      "Train Epoch: 1 120 0.1883\n",
      "Train Epoch: 1 130 0.3352\n",
      "Train Epoch: 1 140 0.3166\n",
      "Train Epoch: 1 150 0.2942\n",
      "Train Epoch: 1 160 0.4287\n",
      "Train Epoch: 1 170 0.1172\n",
      "Train Epoch: 1 180 0.2434\n",
      "Train Epoch: 1 190 0.1415\n",
      "Train Epoch: 1 200 0.272\n",
      "Train Epoch: 1 210 0.1054\n",
      "Train Epoch: 1 220 0.1112\n",
      "Train Epoch: 1 230 0.08716\n",
      "Train Epoch: 1 240 0.2709\n",
      "Train Epoch: 1 250 0.184\n",
      "Train Epoch: 1 260 0.1849\n",
      "Train Epoch: 1 270 0.2548\n",
      "Train Epoch: 1 280 0.2575\n",
      "Train Epoch: 1 290 0.2281\n",
      "Train Epoch: 1 300 0.207\n",
      "Train Epoch: 1 310 0.1762\n",
      "Train Epoch: 1 320 0.09062\n",
      "Train Epoch: 1 330 0.3141\n",
      "Train Epoch: 1 340 0.2422\n",
      "Train Epoch: 1 350 0.1216\n",
      "Train Epoch: 1 360 0.2012\n",
      "Train Epoch: 1 370 0.2311\n",
      "Train Epoch: 1 380 0.06838\n",
      "Train Epoch: 1 390 0.4122\n",
      "Train Epoch: 1 400 0.1347\n",
      "Train Epoch: 1 410 0.02331\n",
      "Train Epoch: 1 420 0.1027\n",
      "Train Epoch: 1 430 0.08022\n",
      "Train Epoch: 1 440 0.07172\n",
      "Train Epoch: 1 450 0.2887\n",
      "Train Epoch: 1 460 0.01545\n",
      "batch_idx >= train_batches, breaking\n",
      "Epoch time: 62 seconds\n",
      "Round Number: 3\n",
      "client Number: 1\n",
      "Epoch: 1\n",
      "> Running train in 469 batches\n",
      "Train Epoch: 1 0 2.293\n",
      "Train Epoch: 1 10 2.019\n",
      "Train Epoch: 1 20 1.113\n",
      "Train Epoch: 1 30 0.5526\n",
      "Train Epoch: 1 40 0.6366\n",
      "Train Epoch: 1 50 0.3979\n",
      "Train Epoch: 1 60 0.4524\n",
      "Train Epoch: 1 70 0.2257\n",
      "Train Epoch: 1 80 0.331\n",
      "Train Epoch: 1 90 0.4575\n",
      "Train Epoch: 1 100 0.3628\n",
      "Train Epoch: 1 110 0.4645\n",
      "Train Epoch: 1 120 0.4511\n",
      "Train Epoch: 1 130 0.3202\n",
      "Train Epoch: 1 140 0.1673\n",
      "Train Epoch: 1 150 0.3456\n",
      "Train Epoch: 1 160 0.1022\n",
      "Train Epoch: 1 170 0.06675\n",
      "Train Epoch: 1 180 0.2205\n",
      "Train Epoch: 1 190 0.1581\n",
      "Train Epoch: 1 200 0.3106\n",
      "Train Epoch: 1 210 0.3192\n",
      "Train Epoch: 1 220 0.3596\n",
      "Train Epoch: 1 230 0.2256\n",
      "Train Epoch: 1 240 0.1518\n",
      "Train Epoch: 1 250 0.1859\n",
      "Train Epoch: 1 260 0.06133\n",
      "Train Epoch: 1 270 0.2013\n",
      "Train Epoch: 1 280 0.1393\n",
      "Train Epoch: 1 290 0.1172\n",
      "Train Epoch: 1 300 0.05548\n",
      "Train Epoch: 1 310 0.1461\n",
      "Train Epoch: 1 320 0.133\n",
      "Train Epoch: 1 330 0.273\n",
      "Train Epoch: 1 340 0.2189\n",
      "Train Epoch: 1 350 0.2159\n",
      "Train Epoch: 1 360 0.2055\n",
      "Train Epoch: 1 370 0.1936\n",
      "Train Epoch: 1 380 0.09898\n",
      "Train Epoch: 1 390 0.15\n",
      "Train Epoch: 1 400 0.1477\n",
      "Train Epoch: 1 410 0.1225\n",
      "Train Epoch: 1 420 0.2527\n",
      "Train Epoch: 1 430 0.0923\n",
      "Train Epoch: 1 440 0.1049\n",
      "Train Epoch: 1 450 0.2505\n",
      "Train Epoch: 1 460 0.118\n",
      "batch_idx >= train_batches, breaking\n",
      "Epoch time: 63 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running test_local in 2 batches\n",
      "batch_idx >= test_batches, breaking\n",
      "Test Set Accuracy: 2.54%\n",
      "Round Number: 4\n",
      "client Number: 0\n",
      "Epoch: 1\n",
      "> Running train in 469 batches\n",
      "Train Epoch: 1 0 2.292\n",
      "Train Epoch: 1 10 1.775\n",
      "Train Epoch: 1 20 0.8218\n",
      "Train Epoch: 1 30 0.4373\n",
      "Train Epoch: 1 40 0.4484\n",
      "Train Epoch: 1 50 0.403\n",
      "Train Epoch: 1 60 0.3707\n",
      "Train Epoch: 1 70 0.2017\n",
      "Train Epoch: 1 80 0.1687\n",
      "Train Epoch: 1 90 0.6354\n",
      "Train Epoch: 1 100 0.2367\n",
      "Train Epoch: 1 110 0.1892\n",
      "Train Epoch: 1 120 0.2775\n",
      "Train Epoch: 1 130 0.4715\n",
      "Train Epoch: 1 140 0.3589\n",
      "Train Epoch: 1 150 0.1605\n",
      "Train Epoch: 1 160 0.4568\n",
      "Train Epoch: 1 170 0.1669\n",
      "Train Epoch: 1 180 0.2684\n",
      "Train Epoch: 1 190 0.05584\n",
      "Train Epoch: 1 200 0.3822\n",
      "Train Epoch: 1 210 0.1409\n",
      "Train Epoch: 1 220 0.06109\n",
      "Train Epoch: 1 230 0.0504\n",
      "Train Epoch: 1 240 0.3342\n",
      "Train Epoch: 1 250 0.1915\n",
      "Train Epoch: 1 260 0.2127\n",
      "Train Epoch: 1 270 0.2771\n",
      "Train Epoch: 1 280 0.1933\n",
      "Train Epoch: 1 290 0.2085\n",
      "Train Epoch: 1 300 0.1011\n",
      "Train Epoch: 1 310 0.1136\n",
      "Train Epoch: 1 320 0.2078\n",
      "Train Epoch: 1 330 0.1885\n",
      "Train Epoch: 1 340 0.2114\n",
      "Train Epoch: 1 350 0.1082\n",
      "Train Epoch: 1 360 0.1535\n",
      "Train Epoch: 1 370 0.2019\n",
      "Train Epoch: 1 380 0.06008\n",
      "Train Epoch: 1 390 0.3035\n",
      "Train Epoch: 1 400 0.1937\n",
      "Train Epoch: 1 410 0.05343\n",
      "Train Epoch: 1 420 0.0602\n",
      "Train Epoch: 1 430 0.03335\n",
      "Train Epoch: 1 440 0.04693\n",
      "Train Epoch: 1 450 0.1774\n",
      "Train Epoch: 1 460 0.005404\n",
      "batch_idx >= train_batches, breaking\n",
      "Epoch time: 62 seconds\n",
      "Round Number: 4\n",
      "client Number: 1\n",
      "Epoch: 1\n",
      "> Running train in 469 batches\n",
      "Train Epoch: 1 0 2.292\n",
      "Train Epoch: 1 10 2.242\n",
      "Train Epoch: 1 20 1.258\n",
      "Train Epoch: 1 30 0.4226\n",
      "Train Epoch: 1 40 0.6302\n",
      "Train Epoch: 1 50 0.4328\n",
      "Train Epoch: 1 60 0.4374\n",
      "Train Epoch: 1 70 0.2019\n",
      "Train Epoch: 1 80 0.3994\n",
      "Train Epoch: 1 90 0.4864\n",
      "Train Epoch: 1 100 0.2351\n",
      "Train Epoch: 1 110 0.3362\n",
      "Train Epoch: 1 120 0.3677\n",
      "Train Epoch: 1 130 0.2927\n",
      "Train Epoch: 1 140 0.2643\n",
      "Train Epoch: 1 150 0.321\n",
      "Train Epoch: 1 160 0.07319\n",
      "Train Epoch: 1 170 0.1119\n",
      "Train Epoch: 1 180 0.2003\n",
      "Train Epoch: 1 190 0.05923\n",
      "Train Epoch: 1 200 0.2666\n",
      "Train Epoch: 1 210 0.2679\n",
      "Train Epoch: 1 220 0.3036\n",
      "Train Epoch: 1 230 0.2136\n",
      "Train Epoch: 1 240 0.1977\n",
      "Train Epoch: 1 250 0.1693\n",
      "Train Epoch: 1 260 0.07135\n",
      "Train Epoch: 1 270 0.2029\n",
      "Train Epoch: 1 280 0.1801\n",
      "Train Epoch: 1 290 0.08692\n",
      "Train Epoch: 1 300 0.07954\n",
      "Train Epoch: 1 310 0.1294\n",
      "Train Epoch: 1 320 0.1608\n",
      "Train Epoch: 1 330 0.1816\n",
      "Train Epoch: 1 340 0.09054\n",
      "Train Epoch: 1 350 0.2401\n",
      "Train Epoch: 1 360 0.3472\n",
      "Train Epoch: 1 370 0.08892\n",
      "Train Epoch: 1 380 0.06899\n",
      "Train Epoch: 1 390 0.1394\n",
      "Train Epoch: 1 400 0.1936\n",
      "Train Epoch: 1 410 0.08253\n",
      "Train Epoch: 1 420 0.3109\n",
      "Train Epoch: 1 430 0.1097\n",
      "Train Epoch: 1 440 0.1259\n",
      "Train Epoch: 1 450 0.2384\n",
      "Train Epoch: 1 460 0.08276\n",
      "batch_idx >= train_batches, breaking\n",
      "Epoch time: 62 seconds\n",
      "> Running test_local in 2 batches\n",
      "batch_idx >= test_batches, breaking\n",
      "Test Set Accuracy: 2.54%\n",
      "Finished Training\n",
      "CPU times: user 5min 54s, sys: 10.3 s, total: 6min 5s\n",
      "Wall time: 10min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import time\n",
    "args[\"dry_run\"] = False  # comment to do a full train\n",
    "print(\"Starting Training\")\n",
    "\n",
    "for fed_round in range(args['rounds']):\n",
    "    for i, client in enumerate(clients):\n",
    "        print(\"Round Number:\",fed_round+1)\n",
    "        client['remote_model'] = client['model'].send(client['duet']).cpu()\n",
    "        client['optim'] = client['remote_torch'].optim.Adadelta(client['remote_model'].parameters(), lr=args['lr'])\n",
    "        client['sched'] = client['remote_torch'].optim.lr_scheduler.StepLR(client['optim'], step_size=1, gamma=args['gamma'])\n",
    "        \n",
    "        # train the clients\\\n",
    "        print(\"client Number:\",i)\n",
    "        for epoch in range(1, args[\"epochs\"] + 1):\n",
    "            epoch_start = time.time()\n",
    "            print(f\"Epoch: {epoch}\")\n",
    "            # remote training on model with remote_torch\n",
    "            train(client, epoch, args)\n",
    "            client['sched'].step()\n",
    "            epoch_end = time.time()\n",
    "            print(f\"Epoch time: {int(epoch_end - epoch_start)} seconds\")\n",
    "            break\n",
    "        \n",
    "        # get the client model back for averaging\n",
    "        client['model'] = client['remote_model'].get(\n",
    "            request_block=True,\n",
    "            reason=\"test evaluation\",\n",
    "            timeout_secs=5\n",
    "        )\n",
    "\n",
    "    # Average all the clients\n",
    "    local_model = averageModels(local_model, clients)\n",
    "    \n",
    "    # local testing on model with local torch\n",
    "    test_local(client, client['model'], client['test_loader_ptr'], client['test_data_length'])\n",
    "    \n",
    "    # Share the global model with the clients\n",
    "    for client in clients:\n",
    "        client['model'].load_state_dict(copy.deepcopy(local_model.state_dict()))\n",
    "    \n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a365039",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pysyft2",
   "language": "python",
   "name": "pysyft2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
