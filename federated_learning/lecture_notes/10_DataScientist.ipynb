{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b654e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft as sy\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb39e9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎤  🎸  ♪♪♪ Joining Duet ♫♫♫  🎻  🎹\n",
      "\n",
      "♫♫♫ >\u001b[93m DISCLAIMER\u001b[0m: \u001b[1mDuet is an experimental feature currently in beta.\n",
      "♫♫♫ > Use at your own risk.\n",
      "\u001b[0m\n",
      "\u001b[1m\n",
      "    > ❤️ \u001b[91mLove\u001b[0m \u001b[92mDuet\u001b[0m? \u001b[93mPlease\u001b[0m \u001b[94mconsider\u001b[0m \u001b[95msupporting\u001b[0m \u001b[91mour\u001b[0m \u001b[93mcommunity!\u001b[0m\n",
      "    > https://github.com/sponsors/OpenMined\u001b[1m\n",
      "\n",
      "♫♫♫ > Punching through firewall to OpenGrid Network Node at:\n",
      "♫♫♫ > http://ec2-18-218-7-180.us-east-2.compute.amazonaws.com:5000\n",
      "♫♫♫ >\n",
      "♫♫♫ > ...waiting for response from OpenGrid Network... \n",
      "♫♫♫ > \u001b[92mDONE!\u001b[0m\n",
      "\n",
      "♫♫♫ > \u001b[95mSTEP 1:\u001b[0m Send the following Duet Client ID to your duet partner!\n",
      "♫♫♫ > Duet Client ID: \u001b[1m25203aab2bd357dcfcd2556ed5c439ef\u001b[0m\n",
      "\n",
      "♫♫♫ > ...waiting for partner to connect...\n",
      "\n",
      "♫♫♫ > \u001b[92mCONNECTED!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "duet = sy.join_duet(\"53c69930c0ee494aeb75a9b044f8fd5d\")\n",
    "sy.logger.add(sink=\"./syft_ds.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "721ca3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "065cbb0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Description</th>\n",
       "      <th>object_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;UID: 6ccc4a72a723483382388a9d0ad9884f&gt;</td>\n",
       "      <td>[x_train]</td>\n",
       "      <td>Dataset of 30000 samples</td>\n",
       "      <td>&lt;class 'torch.Tensor'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;UID: d1e7beee877d460da4ce54116876c340&gt;</td>\n",
       "      <td>[y_train]</td>\n",
       "      <td>Dataset of 30000 samples</td>\n",
       "      <td>&lt;class 'torch.Tensor'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;UID: f0e2e5e86194469cbeababb5a06ffa88&gt;</td>\n",
       "      <td>[x_test]</td>\n",
       "      <td>Dataset of 5000 samples</td>\n",
       "      <td>&lt;class 'torch.Tensor'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;UID: 09043f3804084d3ba45a6c522d041275&gt;</td>\n",
       "      <td>[y_test]</td>\n",
       "      <td>Dataset of 5000 samples</td>\n",
       "      <td>&lt;class 'torch.Tensor'&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        ID       Tags  \\\n",
       "0  <UID: 6ccc4a72a723483382388a9d0ad9884f>  [x_train]   \n",
       "1  <UID: d1e7beee877d460da4ce54116876c340>  [y_train]   \n",
       "2  <UID: f0e2e5e86194469cbeababb5a06ffa88>   [x_test]   \n",
       "3  <UID: 09043f3804084d3ba45a6c522d041275>   [y_test]   \n",
       "\n",
       "                Description             object_type  \n",
       "0  Dataset of 30000 samples  <class 'torch.Tensor'>  \n",
       "1  Dataset of 30000 samples  <class 'torch.Tensor'>  \n",
       "2   Dataset of 5000 samples  <class 'torch.Tensor'>  \n",
       "3   Dataset of 5000 samples  <class 'torch.Tensor'>  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duet.store.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1afde37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cnn 모델을 사용\n",
    "class SyNet(sy.Module):\n",
    "    def __init__(self, torch_ref):\n",
    "        super(SyNet, self).__init__(torch_ref=torch_ref)\n",
    "        self.conv1 = self.torch_ref.nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = self.torch_ref.nn.Conv2d(32, 64, 3, 1) \n",
    "        self.conv3 = self.torch_ref.nn.Conv2d(64, 128, 3 ,1)\n",
    "        \n",
    "        self.dropout1 = self.torch_ref.nn.Dropout2d(0.25)\n",
    "        self.dropout2 = self.torch_ref.nn.Dropout2d(0.5)\n",
    "        \n",
    "        self.fc1 = self.torch_ref.nn.Linear(9216, 128)\n",
    "        self.fc2 = self.torch_ref.nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # ImgIn shape=(?, 1, 28, 28)\n",
    "        # Conv     -> (?, 32, 28, 28)\n",
    "        x = self.conv1(x)\n",
    "        x = self.torch_ref.nn.functional.relu(x)\n",
    "        # ImgIn shape=(?, 32, 28, 28)\n",
    "        # Conv     -> (?, 64, 28, 28)\n",
    "        # Pool     -> (?, 64, 14, 14)\n",
    "        x = self.conv2(x)\n",
    "        x = self.torch_ref.nn.functional.relu(x)\n",
    "        x = self.torch_ref.nn.functional.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        # Flatten     -> (?, 64*14*14)\n",
    "        x = self.torch_ref.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.torch_ref.nn.functional.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = self.torch_ref.nn.functional.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f07187e",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_model = SyNet(torch) #local에 보낼 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78f8eb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = local_model.send(duet) #생성한 모델을 duet을 통해 local에 전송\n",
    "remote_torch = duet.torch #데이터 오너의 torch사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "907ddca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습에 사용될 인자들 설정\n",
    "args = {\n",
    "    \"batch_size\": 64,\n",
    "    \"test_batch_size\": 5000,\n",
    "    \"epochs\": 40,\n",
    "    \"lr\": 1.0,\n",
    "    \"gamma\": 0.7,\n",
    "    \"dry_run\": False,\n",
    "    \"seed\": 42, # the meaning of life\n",
    "    \"log_interval\": 10,\n",
    "    \"save_model\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fbf591b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000 30000\n",
      "30000\n"
     ]
    }
   ],
   "source": [
    "#train 데이터셋 얻기\n",
    "train_kwargs = {\n",
    "    \"batch_size\": args[\"batch_size\"],\n",
    "}\n",
    "#duet에 0번째, 1번째가 x_train, y_train\n",
    "print(len(duet.store[0]), len(duet.store[1]))\n",
    "#듀엣에 보관중인 데이터는 torch.Tensor형태이므로 \n",
    "#이 두개를 묶어서 x와 y가 모두 포함된 Dataset을 만들고 \n",
    "#Dataset을 다시 DataLoader를 만들어서 모델의 입력으로 넣어줄 수 있도록 변환해줌\n",
    "train_data_ptr=torch.utils.data.TensorDataset(duet.store[0].get_copy(), duet.store[1].get_copy())\n",
    "train_loader_ptr = torch.utils.data.DataLoader(train_data_ptr,**train_kwargs)\n",
    "train_data_length = len(train_loader_ptr.dataset)\n",
    "print(train_data_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbd75b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 5000\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "#test데이터셋 얻기\n",
    "test_kwargs = {\n",
    "    \"batch_size\": args[\"test_batch_size\"],\n",
    "}\n",
    "#duet에 2번째, 3번째가 x_test, y_test\n",
    "print(len(duet.store[2]), len(duet.store[3]))\n",
    "\n",
    "test_data=torch.utils.data.TensorDataset(duet.store[2].get_copy(), duet.store[3].get_copy())\n",
    "test_loader = torch.utils.data.DataLoader(test_data, **test_kwargs)\n",
    "test_data_length = len(test_loader.dataset)\n",
    "print(test_data_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3eccb1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = model.parameters()\n",
    "optimizer = remote_torch.optim.Adadelta(params, lr=args[\"lr\"])\n",
    "scheduler = remote_torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=args[\"gamma\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3cefde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, torch_ref, train_loader, optimizer, epoch, args, train_data_length):\n",
    "    train_batches = round((train_data_length / args[\"batch_size\"]) + 0.5) #올림작업을 하기위한 +0.5\n",
    "    print(f\"> Running train in {train_batches} batches\")\n",
    "    if model.is_local:\n",
    "        print(\"Training requires remote model\")\n",
    "        return\n",
    "\n",
    "    model.train() #학습 알림\n",
    "\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        data_ptr, target_ptr = data[0], data[1]\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data_ptr)\n",
    "        loss = torch_ref.nn.functional.nll_loss(output, target_ptr)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_item = loss.item()\n",
    "        train_loss = duet.python.Float(0)  #Float\n",
    "        train_loss += loss_item\n",
    "        if batch_idx % args[\"log_interval\"] == 0:\n",
    "            local_loss = None\n",
    "            local_loss = loss_item.get(\n",
    "                reason=\"To evaluate training progress\",\n",
    "                request_block=True,\n",
    "                timeout_secs=5\n",
    "            )\n",
    "            if local_loss is not None:\n",
    "                print(\"Train Epoch: {} {} {:.4}\".format(epoch, batch_idx, local_loss))\n",
    "            else:\n",
    "                print(\"Train Epoch: {} {} ?\".format(epoch, batch_idx))\n",
    "            if args[\"dry_run\"]:\n",
    "                break\n",
    "        if batch_idx >= train_batches - 1:\n",
    "            print(\"batch_idx >= train_batches, breaking\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ee0ab2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_local(model, torch_ref, test_loader, test_data_length):\n",
    "    # download remote model\n",
    "    if not model.is_local:\n",
    "        local_model = model.get(\n",
    "            request_block=True,\n",
    "            reason=\"test evaluation\",\n",
    "            timeout_secs=5\n",
    "        )\n",
    "    else:\n",
    "        local_model = model\n",
    "    # + 0.5 lets us math.ceil without the import\n",
    "    test_batches = round((test_data_length / args[\"test_batch_size\"]) + 0.5)\n",
    "    print(f\"> Running test_local in {test_batches} batches\")\n",
    "    local_model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0.0\n",
    "\n",
    "    with torch_ref.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(test_loader):\n",
    "            output = local_model(data)\n",
    "            iter_loss = torch_ref.nn.functional.nll_loss(output, target, reduction=\"sum\").item()\n",
    "            test_loss = test_loss + iter_loss\n",
    "            pred = output.argmax(dim=1)\n",
    "            total = pred.eq(target).sum().item()\n",
    "            correct += total\n",
    "            if args[\"dry_run\"]:\n",
    "                break\n",
    "                \n",
    "            if batch_idx >= test_batches - 1:\n",
    "                print(\"batch_idx >= test_batches, breaking\")\n",
    "                break\n",
    "\n",
    "    accuracy = correct / test_data_length\n",
    "    print(f\"Test Set Accuracy: {100 * accuracy}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "88038108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training\n",
      "Epoch: 1\n",
      "> Running train in 469 batches\n",
      "Train Epoch: 1 0 2.309\n",
      "Train Epoch: 1 10 2.004\n",
      "Train Epoch: 1 20 1.181\n",
      "Train Epoch: 1 30 0.5613\n",
      "Train Epoch: 1 40 0.6126\n",
      "Train Epoch: 1 50 0.4565\n",
      "Train Epoch: 1 60 0.5415\n",
      "Train Epoch: 1 70 0.3528\n",
      "Train Epoch: 1 80 0.3757\n",
      "Train Epoch: 1 90 0.7534\n",
      "Train Epoch: 1 100 0.3522\n",
      "Train Epoch: 1 110 0.2441\n",
      "Train Epoch: 1 120 0.2844\n",
      "Train Epoch: 1 130 0.3704\n",
      "Train Epoch: 1 140 0.3851\n",
      "Train Epoch: 1 150 0.2367\n",
      "Train Epoch: 1 160 0.2693\n",
      "Train Epoch: 1 170 0.1395\n",
      "Train Epoch: 1 180 0.1822\n",
      "Train Epoch: 1 190 0.1782\n",
      "Train Epoch: 1 200 0.4341\n",
      "Train Epoch: 1 210 0.08853\n",
      "Train Epoch: 1 220 0.1022\n",
      "Train Epoch: 1 230 0.03211\n",
      "Train Epoch: 1 240 0.2129\n",
      "Train Epoch: 1 250 0.1511\n",
      "Train Epoch: 1 260 0.2294\n",
      "Train Epoch: 1 270 0.223\n",
      "Train Epoch: 1 280 0.3243\n",
      "Train Epoch: 1 290 0.2877\n",
      "Train Epoch: 1 300 0.1102\n",
      "Train Epoch: 1 310 0.1707\n",
      "Train Epoch: 1 320 0.097\n",
      "Train Epoch: 1 330 0.1867\n",
      "Train Epoch: 1 340 0.1699\n",
      "Train Epoch: 1 350 0.1226\n",
      "Train Epoch: 1 360 0.1867\n",
      "Train Epoch: 1 370 0.2315\n",
      "Train Epoch: 1 380 0.0536\n",
      "Train Epoch: 1 390 0.4888\n",
      "Train Epoch: 1 400 0.2149\n",
      "Train Epoch: 1 410 0.0648\n",
      "Train Epoch: 1 420 0.06831\n",
      "Train Epoch: 1 430 0.05568\n",
      "Train Epoch: 1 440 0.05959\n",
      "Train Epoch: 1 450 0.2283\n",
      "Train Epoch: 1 460 0.02127\n",
      "batch_idx >= train_batches, breaking\n",
      "> Running test_local in 2 batches\n",
      "Test Set Accuracy: 97.66%\n",
      "Epoch time: 76 seconds\n",
      "Finished Training\n",
      "CPU times: user 45.4 s, sys: 2.36 s, total: 47.8 s\n",
      "Wall time: 1min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import time\n",
    "\n",
    "args[\"dry_run\"] = False  # comment to do a full train\n",
    "print(\"Starting Training\")\n",
    "for epoch in range(1, args[\"epochs\"] + 1):\n",
    "    epoch_start = time.time()\n",
    "    print(f\"Epoch: {epoch}\")\n",
    "    #로컬 훈련\n",
    "    train(model, remote_torch, train_loader_ptr, optimizer, epoch, args, train_data_length)\n",
    "    #로컬 테스트\n",
    "    test_local(model, torch, test_loader, test_data_length)\n",
    "    scheduler.step()\n",
    "    epoch_end = time.time()\n",
    "    print(f\"Epoch time: {int(epoch_end - epoch_start)} seconds\")\n",
    "    break\n",
    "print(\"Finished Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4529f76f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pysyft2",
   "language": "python",
   "name": "pysyft2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
